{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. parsing dokumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read each chats session folder path\n",
    "\"\"\" 1. list folder chatx DONE\n",
    "    2. list file dalam folder\n",
    "    \n",
    "    EXPECTED:\n",
    "    current dir + /parsed doc/ + chatx/ + sesix.txt    \n",
    "\"\"\"\n",
    "parsed_doc_path = '../parsing/parsed_doc/'\n",
    "chat_folders = [chat_folder for chat_folder in os.listdir(parsed_doc_path) if not chat_folder.startswith('.')]\n",
    "\n",
    "paths = []\n",
    "for chat_folder in chat_folders:\n",
    "    pattern = parsed_doc_path + chat_folder\n",
    "    paths.append(pattern)\n",
    "    \n",
    "sesi_paths = []\n",
    "for path in paths:\n",
    "    for roots, dirs, files in os.walk(path):\n",
    "        if \"checkpoints\" not in roots:\n",
    "            for file in files:\n",
    "                sesi_paths.append(roots + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make list of dataframe for each chats session\n",
    "sessions = list()\n",
    "for sesi_path in sesi_paths:\n",
    "    sesi = pd.read_csv(sesi_path, sep='|', names=['sender', 'messages', 'sentiment'])\n",
    "    sesi.drop('sender', axis=1, inplace=True) ## drop sender column (since its not necessary)\n",
    "    sessions.append(sesi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assalamualaikum Wr. Wb. Pak, selamat pagi, moh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wa'alaykumsalam. Via wa ini sj ya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baik Pak. Perihal waktu bimbingannya sendiri, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biasanya hari Kamis atau Jumat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baik Pak. Lalu untuk pelaksanaan P0, apakah te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  sentiment\n",
       "0  Assalamualaikum Wr. Wb. Pak, selamat pagi, moh...          1\n",
       "1                  Wa'alaykumsalam. Via wa ini sj ya          1\n",
       "2  Baik Pak. Perihal waktu bimbingannya sendiri, ...          1\n",
       "3                     Biasanya hari Kamis atau Jumat          1\n",
       "4  Baik Pak. Lalu untuk pelaksanaan P0, apakah te...          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. lexical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lexical analysis - cleaning\n",
    "def cleaning(message):\n",
    "    \"\"\" This function will remove unnecessaries values in the messages i.e links, emails, and punctuations\n",
    "    \"\"\"\n",
    "    link_reg = r'(https?:\\/\\/[^\\s]+)|(www\\.[^\\s]+)|(meet\\.google\\.[^\\s]+)|(bit\\.ly[^\\s]+)'\n",
    "    email_reg = r'([a-zA-Z0-9\\.\\_\\-]+@+[a-zA-Z0-9.]+)'\n",
    "    punct_reg = r'[^a-zA-Z0-9\\[\\]]'\n",
    "    numb_reg = r'\\b[0-9]+\\b\\s*'\n",
    "    \n",
    "    message = re.sub(link_reg, '', message) # -> link removed\n",
    "    message = re.sub(email_reg, '', message) # -> email removed\n",
    "    message = re.sub(punct_reg, ' ', message) # -> punctuation removed\n",
    "    message = re.sub(numb_reg, '', message) # -> numbers removed\n",
    "    \n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lexical analysis - tokenization\n",
    "def tokenize(message, token_list):\n",
    "    \"\"\" This function will turns all sentences into token or word.\n",
    "        Each messages will saved in a list.\n",
    "    \"\"\"\n",
    "    word_list = re.split('\\s+', message)\n",
    "    for word in word_list:\n",
    "        if word not in token_list:\n",
    "            token_list.append(word)\n",
    "    \n",
    "    return word_list, token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do lexical analysis\n",
    "for sesi in sessions:\n",
    "    for i, row in sesi.iterrows():\n",
    "        message = row['messages']\n",
    "        # do cleaning\n",
    "        message = cleaning(message)\n",
    "        # do lower case\n",
    "        message = message.lower()\n",
    "        # do tokenization\n",
    "        message = re.split('\\s+', message)\n",
    "\n",
    "        #replace current message value in df\n",
    "        sesi.at[i, 'messages'] = message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[assalamualaikum, wr, wb, pak, selamat, pagi, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[wa, alaykumsalam, via, wa, ini, sj, ya]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[baik, pak, perihal, waktu, bimbingannya, send...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[biasanya, hari, kamis, atau, jumat]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[baik, pak, lalu, untuk, pelaksanaan, p0, apak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  sentiment\n",
       "0  [assalamualaikum, wr, wb, pak, selamat, pagi, ...          1\n",
       "1           [wa, alaykumsalam, via, wa, ini, sj, ya]          1\n",
       "2  [baik, pak, perihal, waktu, bimbingannya, send...          1\n",
       "3               [biasanya, hari, kamis, atau, jumat]          1\n",
       "4  [baik, pak, lalu, untuk, pelaksanaan, p0, apak...          1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. normalization (slang word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalize function\n",
    "def normalize(slang_words, tokens):\n",
    "    \"\"\" This function will normalize the tokens,\n",
    "        it will turn the slang words or typos to its normal values.\n",
    "        NOTE: you could add the values into json files.\n",
    "    \"\"\"\n",
    "    new_tokens = list()\n",
    "    for token in tokens:\n",
    "        new_value = slang_words.get(token, token) #2nd parameter for default value if word's key not found\n",
    "        new_tokens.append(new_value)\n",
    "    \n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## open slang_words json\n",
    "f = open('slang_words.json', 'r')\n",
    "slang_words = json.load(f)\n",
    "f.close()\n",
    "\n",
    "## do normalize\n",
    "for sesi in sessions:\n",
    "    for i, row in sesi.iterrows():\n",
    "        tokens = row['messages']\n",
    "        # do normalize\n",
    "        new_tokens = normalize(slang_words, tokens)\n",
    "\n",
    "        #replace current message value in df\n",
    "        sesi.at[i, 'messages'] = new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[assalamualaikum, wr, wb, bapak, selamat, pagi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[wa, alaykumsalam, via, wa, ini, saja, iya]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[baik, bapak, perihal, waktu, bimbingannya, se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[biasanya, hari, kamis, atau, jumat]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[baik, bapak, lalu, untuk, pelaksanaan, p0, ap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  sentiment\n",
       "0  [assalamualaikum, wr, wb, bapak, selamat, pagi...          1\n",
       "1        [wa, alaykumsalam, via, wa, ini, saja, iya]          1\n",
       "2  [baik, bapak, perihal, waktu, bimbingannya, se...          1\n",
       "3               [biasanya, hari, kamis, atau, jumat]          1\n",
       "4  [baik, bapak, lalu, untuk, pelaksanaan, p0, ap...          1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filtering function\n",
    "def filtering(stopword_list, tokens):\n",
    "    \"\"\" Filtering: removing stopwords from tokens.\n",
    "        In this project, we will use tala stopwords list.\n",
    "    \"\"\"\n",
    "    new_tokens = list()\n",
    "    for token in tokens:\n",
    "        if token not in stopword_list:\n",
    "            new_tokens.append(token)\n",
    "    \n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## open stopword list txt\n",
    "f = open('tala_stopwords.txt', 'r')\n",
    "stopword_list = f.read()\n",
    "f.close()\n",
    "\n",
    "## do normalize\n",
    "for sesi in sessions:\n",
    "    for i, row in sesi.iterrows():\n",
    "        tokens = row['messages']\n",
    "        # do filtering\n",
    "        new_tokens = filtering(stopword_list, tokens)\n",
    "\n",
    "        #replace current message value in df\n",
    "        sesi.at[i, 'messages'] = new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[selamat, pagi, mohon, maaf, mengganggu, mahas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[alaykumsalam, via, iya]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[perihal, bimbingannya, ketentuan, jam]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[kamis, jumat]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[pelaksanaan, p0, ditentukan, dibahas, bimbing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  sentiment\n",
       "0  [selamat, pagi, mohon, maaf, mengganggu, mahas...          1\n",
       "1                           [alaykumsalam, via, iya]          1\n",
       "2            [perihal, bimbingannya, ketentuan, jam]          1\n",
       "3                                     [kamis, jumat]          1\n",
       "4  [pelaksanaan, p0, ditentukan, dibahas, bimbing...          1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stemming function\n",
    "def stemming(stemmer, tokens):\n",
    "    \"\"\" Stemming: returns words to its original form.\n",
    "        Since non-alphanumeric will be discarded by using StemmerFactory(),\n",
    "        This function will do stemming if the token values neither [dosen] nor [mhs].\n",
    "    \"\"\"\n",
    "    new_tokens = list()\n",
    "    for token in tokens:\n",
    "        new_value = stemmer.stem(token)\n",
    "        new_tokens.append(new_value)\n",
    "    \n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create stemmer object\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "## do normalize\n",
    "for sesi in sessions:\n",
    "    for i, row in sesi.iterrows():\n",
    "        tokens = row['messages']\n",
    "        # do filtering\n",
    "        new_tokens = stemming(stemmer, tokens)\n",
    "\n",
    "        #replace current message value in df\n",
    "        sesi.at[i, 'messages'] = new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[selamat, pagi, mohon, maaf, ganggu, mahasiswa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[alaykumsalam, via, iya]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[perihal, bimbing, tentu, jam]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[kamis, jumat]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[laksana, p0, tentu, bahas, bimbing, iya]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  sentiment\n",
       "0  [selamat, pagi, mohon, maaf, ganggu, mahasiswa...          1\n",
       "1                           [alaykumsalam, via, iya]          1\n",
       "2                     [perihal, bimbing, tentu, jam]          1\n",
       "3                                     [kamis, jumat]          1\n",
       "4          [laksana, p0, tentu, bahas, bimbing, iya]          1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. add session index for each chat, also make array of df into single df, using pandas concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add index session column\n",
    "for i, sesi in enumerate(sessions):\n",
    "    index = [i for j in range(sesi.shape[0])]\n",
    "    sesi['session_index'] = index\n",
    "\n",
    "## concat all df into single df\n",
    "sessions_final = pd.concat(sessions, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_final.to_csv('preprocessing_3_29.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
