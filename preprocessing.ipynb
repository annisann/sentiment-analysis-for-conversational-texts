{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import fnmatch\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem:\n",
    "- doc_list or file_list or whatever aku gatau gimana cara ngeread semuanya wkwk soalnya waktu itu gabisa, error\n",
    "- sampe stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 1. list folder chatx DONE\n",
    "    2. list file dalam folder\n",
    "    \n",
    "    EXPECTED:\n",
    "    current dir + /parsed doc/ + chatx/ + sesix.txt\n",
    "    \n",
    "\"\"\"\n",
    "folder = os.getcwd() + '/parsed doc/'\n",
    "chat_folders = [chat_folder for chat_folder in os.listdir(folder) if not chat_folder.startswith('.')]\n",
    "\n",
    "paths = []\n",
    "for i in range(len(chat_folders)):\n",
    "    pattern = str(folder) + chat_folders[i]\n",
    "    paths.append(pattern)\n",
    "    \n",
    "sesi_paths = []\n",
    "for i in range(len(paths)):\n",
    "    for roots, dirs, files in os.walk(paths[i]):\n",
    "        if \"checkpoints\" not in roots:\n",
    "            for file in files:\n",
    "                sesi_paths.append(roots + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>messages</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dosen</td>\n",
       "      <td>Baik [MHS],  Silahkan dikirimkan dokumen bimbi...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mahasiswa</td>\n",
       "      <td>Baik bapak, terimakasih banyak informasinya</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sender                                           messages  sentiment\n",
       "0      dosen  Baik [MHS],  Silahkan dikirimkan dokumen bimbi...        1.0\n",
       "1  mahasiswa       Baik bapak, terimakasih banyak informasinya         1.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats = [pd.read_csv(sesi, sep='|', names = ['sender', 'messages', 'sentiment']) for sesi in sesi_paths]\n",
    "chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender = chats['sender'].values.tolist()\n",
    "messages = chats['messages'].values.tolist()\n",
    "sentiment = chats['sentiment'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(msg):\n",
    "    token = [re.split('\\s+', msg[i]) for i, chat in enumerate(msg)]\n",
    "    return token\n",
    "\n",
    "token = tokenize(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def casefolding(msg):\n",
    "    token_lower = [[token.lower() for token in i if token] for i in msg]\n",
    "    return token_lower\n",
    "\n",
    "token_lower = casefolding(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(msg):\n",
    "    link = r'(www\\.[^\\s]+)|(https?:\\/\\/[^\\s]+)|(meet\\.google\\.[^\\s]+)'\n",
    "    email = r'([a-zA-Z0-9\\.\\_\\-]+@+[a-zA-Z0-9.]+)'\n",
    "    punct = r'[^a-zA-Z0-9\\-\\s]'\n",
    "    \n",
    "    token_clean = []\n",
    "    for i in msg:\n",
    "        token_per_chat = []\n",
    "        for token in i:\n",
    "            # remove link\n",
    "            temp = re.sub(link, '', token)\n",
    "            # remove email\n",
    "            temp = re.sub(email, '', temp)\n",
    "            # remove punctuation\n",
    "            temp = re.sub(punct, '', temp)\n",
    "            temp = re.sub(r'\\-', ' ', temp)\n",
    "            # remove numbers\n",
    "            temp = re.sub(r'\\b[0-9]+\\b\\s*', '', temp)\n",
    "            token_per_chat.append(temp)\n",
    "        token_clean.append(token_per_chat)\n",
    "        while('' in token_per_chat): \n",
    "            token_per_chat.remove('')\n",
    "    return token_clean\n",
    "\n",
    "token_clean = cleaning(token_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(msg):\n",
    "    with open('slang_words.json', 'r') as f:\n",
    "        dict = json.load(f)\n",
    "    \n",
    "    normalized_chat = []\n",
    "    for i in msg:\n",
    "        slang_dict = {v:k for v, k in dict.items()}\n",
    "        token_per_chat = []\n",
    "        for token in i:\n",
    "            normal = slang_dict.get(token, token)\n",
    "            token_per_chat.append(normal)\n",
    "        normalized_chat.append(token_per_chat)\n",
    "    return normalized_chat\n",
    "\n",
    "token_normal = normalize(token_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(msg):\n",
    "    with open('stopword_list_tala.txt', 'r') as tala:\n",
    "        stoplist = tala.read()\n",
    "    token_filtered = [[token for token in i if not token in stoplist] for i in msg]\n",
    "    return token_filtered\n",
    "\n",
    "token_filtered = filtering(token_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "def stemming(msg):\n",
    "    token_stemmed = [[stemmer.stem(token) for token in i] for i in msg]\n",
    "    return token_stemmed\n",
    "\n",
    "token_stemmed = stemming(token_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setToken = [set(token) for token in token_stemmed]\n",
    "setToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['selamat',\n",
       "  'pagi',\n",
       "  'mahasiswa',\n",
       "  'semester',\n",
       "  'teknik',\n",
       "  'informatika',\n",
       "  'ub',\n",
       "  'bimbing',\n",
       "  'skripsi',\n",
       "  'mohon',\n",
       "  'bantu',\n",
       "  'verifikasi',\n",
       "  'nilai',\n",
       "  'p2',\n",
       "  'skripsi',\n",
       "  'mohon',\n",
       "  'iya',\n",
       "  'orangtua',\n",
       "  'kendala',\n",
       "  'sulit',\n",
       "  'bisnis',\n",
       "  'situasi',\n",
       "  'covid',\n",
       "  'lulus',\n",
       "  'semester',\n",
       "  'semester',\n",
       "  'berat',\n",
       "  'biaya',\n",
       "  'uang',\n",
       "  'kuliah',\n",
       "  'mohon',\n",
       "  'lanjut',\n",
       "  'tahap',\n",
       "  'seminar',\n",
       "  'hasil',\n",
       "  'semester',\n",
       "  'perhati',\n",
       "  'tolong',\n",
       "  'terima',\n",
       "  'kasih',\n",
       "  'hormat',\n",
       "  'halomoan',\n",
       "  'selamat',\n",
       "  'siang',\n",
       "  'mahasiswa',\n",
       "  'semester',\n",
       "  'teknik',\n",
       "  'informatika',\n",
       "  'ub',\n",
       "  'bimbing',\n",
       "  'skripsi',\n",
       "  'mohon',\n",
       "  'bantu',\n",
       "  'verifikasi',\n",
       "  'nilai',\n",
       "  'p2',\n",
       "  'skripsi',\n",
       "  'mohon',\n",
       "  'orangtua',\n",
       "  'kendala',\n",
       "  'sulit',\n",
       "  'bisnis',\n",
       "  'situasi',\n",
       "  'covid',\n",
       "  'lulus',\n",
       "  'semester',\n",
       "  'semester',\n",
       "  'berat',\n",
       "  'biaya',\n",
       "  'uang',\n",
       "  'kuliah',\n",
       "  'mohon',\n",
       "  'lanjut',\n",
       "  'tahap',\n",
       "  'seminar',\n",
       "  'hasil',\n",
       "  'semester',\n",
       "  'perhati',\n",
       "  'tolong',\n",
       "  'terima',\n",
       "  'kasih',\n",
       "  'hormat'],\n",
       " ['iya'],\n",
       " ['terima', 'kasih'],\n",
       " ['apps', 'informasi', 'iya', 'media', 'serta'],\n",
       " ['media', 'serta'],\n",
       " ['media', 'serta'],\n",
       " ['media', 'serta', 'apps', 'muncul', 'terang'],\n",
       " ['sila', 'cek', 'media', 'serta'],\n",
       " ['terima kasih']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "1\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "4\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in setToken:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
