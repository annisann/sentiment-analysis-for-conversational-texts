{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "changed-channels",
   "metadata": {},
   "source": [
    "## raw_tf.ipynb\n",
    "code for make raw tf csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "likely-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-ministry",
   "metadata": {},
   "source": [
    "### 1. convert messages into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fitting-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "chats_data = pd.read_csv('../2_preprocessing/preprocessing_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "innovative-performance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>session_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['[DOSEN]', 'mohon', 'maaf', 'ganggu', 'nama',...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['sedia', 'topik', 'layak', 'posisi', 'map', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['terima kasih', 'mohon', 'maaf', 'mekanisme',...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['[MHS]', 'silah', 'kirim', 'dokumen', 'bimbin...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['terima kasih', 'informasi']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['[DOSEN]', 'abar', 'kirim', 'vidio', 'present...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['[MHS]', 'cek', 'video', 'p0', 'note', 'p0', ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['terima', 'kasih']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['maaf', 'ganggu', '[DOSEN]', 'abar', 'unggah'...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['[MHS]', 'catat', 'request', 'dosen bimbing',...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages  sentiment  session_index\n",
       "0  ['[DOSEN]', 'mohon', 'maaf', 'ganggu', 'nama',...        1.0              0\n",
       "1  ['sedia', 'topik', 'layak', 'posisi', 'map', '...        1.0              0\n",
       "2  ['terima kasih', 'mohon', 'maaf', 'mekanisme',...       -1.0              0\n",
       "3  ['[MHS]', 'silah', 'kirim', 'dokumen', 'bimbin...        1.0              1\n",
       "4                      ['terima kasih', 'informasi']        1.0              1\n",
       "5  ['[DOSEN]', 'abar', 'kirim', 'vidio', 'present...        1.0              2\n",
       "6  ['[MHS]', 'cek', 'video', 'p0', 'note', 'p0', ...        1.0              2\n",
       "7                                ['terima', 'kasih']        1.0              2\n",
       "8  ['maaf', 'ganggu', '[DOSEN]', 'abar', 'unggah'...        1.0              3\n",
       "9  ['[MHS]', 'catat', 'request', 'dosen bimbing',...        1.0              3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "synthetic-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_list = list()\n",
    "\n",
    "for message in chats_data['messages']:\n",
    "    \n",
    "    message = message.replace('[', '').replace('\\'', '').replace(']', '')\n",
    "    message_list = message.split(', ')\n",
    "    \n",
    "    for i, each in enumerate(message_list):\n",
    "        if each == 'DOSEN' or each == 'MHS' or each == 'LINK':\n",
    "            each = f'[{each}]'\n",
    "            message_list[i] = each\n",
    "            \n",
    "    messages_list.append(message_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "minute-scheduling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total = 1505 chats\n",
      "[['[DOSEN]', 'mohon', 'maaf', 'ganggu', 'nama', '[MHS]', 'angkat', 'sedia', 'bimbing', 'skripsi', 'milik', 'topik', 'sentimen', 'analisis', 'produk', 'layan', 'indihome', 'metode', 'nearest', 'neighbor', 'information', 'topik', 'angkat', 'teliti', 'skripsi', 'terima', 'kasih'], ['sedia', 'topik', 'layak', 'posisi', 'map', 'kaji', 'pustaka'], ['terima kasih', 'mohon', 'maaf', 'mekanisme', 'bimbing', 'daring'], ['[MHS]', 'silah', 'kirim', 'dokumen', 'bimbing', 'minimal', 'minggu', 'pra', 'proposal', 'p0', 'p1', 'p2', 'seminar hasil', 'sidang', 'tolong', 'cantum', 'detail', 'content', 'email', 'lampir', 'draft', 'dokumen', 'dokumen', 'skripsi', 'dlm', 'doc', 'docx', 'power point', 'p0', 'p1', 'p2', 'seminar hasil', 'sidang', 'p0', 'p1', 'p2', 'seminar hasil', 'sidang', 'contoh', 'power point', 'link', 'grup', 'kelas', 'tinggal', 'ganti', 'isi', 'contoh', 'screenshoot', 'hasil', 'running', 'program', 'deskripsi', 'poin', 'revisi', 'deskripsi', 'poin', 'progres', 'selesai', 'dan lain', 'seminar hasil', 'sidang', 'tetap', 'online', 'daring', 'google', 'meet', 'zoom', 'kirim', '[DOSEN]', 'cegah', 'covid', 'ikhtiyar', 'optimal', 'physical', 'social', 'distance', 'hindar', 'minimal', 'kumpul', 'mahasiswa', 'org', 'hindar', 'kelompok', 'stay', 'home', 'kos', 'batas', 'kecuali', 'urgent', 'pakai', 'masker', 'mudik', 'gera', 'hidup', 'sehat', 'bersih', 'dan lain', 'lahir', 'tawakal', 'batin', 'moga', 'sukses', 'skripsi', 'moga', 'hindar', 'bahaya', 'sakit', 'wabah', 'aamiin', 'mohon', 'maaf', 'khilaf', 'jaga', 'sikap', 'sopan', 'santun', 'sejuk', 'terima kasih', '[DOSEN]'], ['terima kasih', 'informasi']]\n"
     ]
    }
   ],
   "source": [
    "print('total =', len(messages_list), 'chats')\n",
    "print(messages_list[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-lyric",
   "metadata": {},
   "source": [
    "### 2. make token set list from messages list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "naked-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_set_list = list()\n",
    "if messages_list:\n",
    "    for message in messages_list:\n",
    "        for word in message:\n",
    "            if word not in token_set_list:\n",
    "                token_set_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "english-family",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total = 1740 unique words\n",
      "['[DOSEN]', 'mohon', 'maaf', 'ganggu', 'nama']\n"
     ]
    }
   ],
   "source": [
    "print('total =', len(token_set_list), 'unique words')\n",
    "print(token_set_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-fetish",
   "metadata": {},
   "source": [
    "### 3. count raw tf each word for each chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "quarterly-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_all_message = list()\n",
    "for message in messages_list:\n",
    "    count_per_message = list()\n",
    "    for token in token_set_list:\n",
    "        tf_token = message.count(token)\n",
    "        count_per_message.append(tf_token)\n",
    "    count_all_message.append(count_per_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pleased-efficiency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total message counted = 1505\n",
      "total word counted from all message = 1740\n"
     ]
    }
   ],
   "source": [
    "print('total message counted =', len(count_all_message))\n",
    "print('total word counted from all message =', len(count_all_message[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-console",
   "metadata": {},
   "source": [
    "### 4. make dataframe for raw tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "protected-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({'tokens':token_set_list})\n",
    "for i, count_per_message in enumerate(count_all_message):\n",
    "    column_title = f'chat_{i}'\n",
    "    result_df[column_title] = count_per_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-bottom",
   "metadata": {},
   "source": [
    "### 5. export df to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "marked-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('raw_tf.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
